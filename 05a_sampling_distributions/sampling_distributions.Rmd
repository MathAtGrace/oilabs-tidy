---
title: "Foundations for statistical inference - Sampling distributions"
runtime: shiny
output:
  html_document:
    css: www/lab.css
    highlight: pygments
    theme: cerulean
    toc: true
    toc_float: true
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, results = FALSE, fig.show = "hide", message = FALSE)

```

In this lab, you will investigate the ways in which the statistics from a random sample of data can serve as point estimates for population parameters.
We're interested in formulating a *sampling distribution* of our estimate in order to learn about the properties of the estimate, such as its distribution.

## Getting Started

### Load packages

In this lab, we will explore and visualize the data using the **tidyverse** suite of packages.
We will also use the **infer** package for resampling.  Only run the code below once in your console.

```{r intall-infer, eval=FALSE}
install.packages("infer")
```


Let's load the packages.  You'll want to add these lines to your lab report.  The last line will help us all have the same answers for our random samples.

```{r load-packages, message=FALSE}
library(tidyverse)
library(openintro)
library(infer)
set.seed(1234)
```

### Creating a reproducible lab report

To create your new lab report, in RStudio, go to New File -\> R Markdown... Then, choose From Template and then choose `Lab Report for OpenIntro Statistics Labs` from the list of templates.

### The data

A 2019 Gallup report states the following:

> The premise that scientific progress benefits people has been embodied in discoveries throughout the ages -- from the development of vaccinations to the explosion of technology in the past few decades, resulting in billions of supercomputers now resting in the hands and pockets of people worldwide.
> Still, not everyone around the world feels science benefits them personally.
>
> **Source:** [World Science Day: Is Knowledge Power?](https://news.gallup.com/opinion/gallup/268121/world-science-day-knowledge-power.aspx)

The Welcome Global Monitor finds that 20% of people globally do not believe that the work scientists do benefits people like them.
In this lab, you will assume this 20% is a true population proportion and learn about how sample proportions can vary from sample to sample by taking smaller samples from the population.
We will first create our population assuming a population size of 100,000.
This means 20,000 (20%) of the population think the work scientists do does not benefit them personally and the remaining 80,000 think it does.

```{r}
global_monitor <- tibble(
  scientist_work = c(rep("Benefits", 80000), rep("Doesn't benefit", 20000))
)
```

The name of the data frame is `global_monitor` and the name of the variable that contains responses to the question *"Do you believe that the work scientists do benefit people like you?"* is `scientist_work`.

We can quickly visualize the distribution of these responses using a bar plot.

```{r bar-plot-pop, fig.height=2.5, fig.width=10}
ggplot(global_monitor, aes(x = scientist_work)) +
  geom_bar() +
  labs(
    x = "", y = "",
    title = "Do you believe that the work scientists do benefit people like you?"
  ) +
  coord_flip() 
```

We can also obtain summary statistics to confirm we constructed the data frame correctly.

```{r summ-stat-pop, results = TRUE}
global_monitor %>%
  count(scientist_work) %>%
  mutate(p = n /sum(n))
```

1.   Add the plot and summary statistics code above into your lab report.

## The unknown sampling distribution

In this lab, you have access to the entire population, but this is rarely the case in real life.
Gathering information on an entire population is often extremely costly or impossible.
Because of this, we often take a sample of the population and use that to understand the properties of the population.

If you are interested in estimating the proportion of people who don't think the work scientists do benefits them, you can use the `sample_n` command to survey the population.

```{r samp1}
samp1 <- global_monitor %>%
  sample_n(50)
```

This command collects a simple random sample of size 50 from the `global_monitor` dataset, and assigns the result to `samp1`.
This is similar to randomly drawing names from a hat that contains the names of all in the population.
Working with these 50 names is considerably simpler than working with all 100,000 people in the population.

If you're interested in estimating the proportion of all people who do not believe that the work scientists do benefits them, but you do not have access to the population data, your best single guess is the sample proportion.

```{r phat-samp1}
samp1 %>%
  count(scientist_work) %>%
  mutate(p_hat = n /sum(n))
```

2.   How does your `p_hat` compare to the true proportion?

The code below will save our $\hat{p}_{\text{samp1}}$ for later under the name `samp1_p_hat`.

```{r inline-calc, include=FALSE}
# For use inline below
samp1_p_hat <- samp1 %>% 
  count(scientist_work) %>% 
  mutate(p_hat = n /sum(n)) %>% 
  filter(scientist_work == "Doesn't benefit") %>% 
  pull(p_hat) %>% 
  round(2)
```

Depending on which 50 people you selected, your estimate could be a bit above or a bit below the true population proportion of `r samp1_p_hat`.
In general, though, the sample proportion turns out to be a pretty good estimate of the true population proportion, and you were able to get it by sampling less than 1% of the population.

3.   If you took a second sample of size 50, would you expect to get exactly the same results as the first time? Why, or why not? If the answer is no, would you expect the proportions to be somewhat different or very different?

4.  Take a second sample, also of size 50, and call it `samp2`. How does the sample proportion of `samp2` compare with that of `samp1`?

5.  Suppose we took two more samples, one of size 100 and one of size 1000. Which would you think would provide a more accurate estimate of the population proportion?

Not surprisingly, every time you take another random sample, you might get a different sample proportion.
It's useful to get a sense of just how much variability you should expect when estimating the population mean this way.
The distribution of sample proportions, called the *sampling distribution (of the proportion)*, can help you understand this variability.
In this lab, because you have access to the population, you can build up the sampling distribution for the sample proportion by repeating the above steps many times.
Here, we use R to take 15,000 different samples of size 50 from the population, calculate the proportion of responses in each sample, filter for only the *Doesn't benefit* responses, and store each result in a vector called `sample_props50`.
Note that we specify that `replace = TRUE` since sampling distributions are constructed by sampling with replacement.

```{r iterate}
sample_props50 <- global_monitor %>%
                    rep_sample_n(size = 50,
                                 reps = 15000,
                                 replace = TRUE) %>%
                    count(scientist_work) %>%
                    mutate(p_hat = n /sum(n)) %>%
                    filter(scientist_work == "Doesn't benefit")
```

And we can visualize the distribution of these proportions with a histogram.

```{r fig.show="hide"}
ggplot(data = sample_props50, aes(x = p_hat)) +
  geom_histogram(binwidth = 0.02) +
  labs(
    x = "p_hat (Doesn't benefit)",
    title = "Sampling distribution of p_hat",
    subtitle = "Sample size = 50, Number of samples = 15000"
  )
```

Next, you will review how this set of code works.

6.  How many elements are there in `sample_props50`? Describe the sampling distribution, and be sure to specifically note its center. Make sure to include a plot of the distribution in your answer.


## Sample size and the sampling distribution

Mechanics aside, let's return to the reason we used the `rep_sample_n` function: to compute a sampling distribution, specifically, the sampling distribution of the proportions from samples of 50 people.

```{r hist, fig.show='hide'}
ggplot(data = sample_props50, aes(x = p_hat)) +
  geom_histogram(binwidth = 0.02)
```

The sampling distribution that you computed tells you much about estimating the true proportion of people who think that the work scientists do doesn't benefit them.
Because the sample proportion is an unbiased estimator, the sampling distribution is centered at the true population proportion, and the spread of the distribution indicates how much variability is incurred by sampling only 50 people at a time from the population.

In the remainder of this section, you will work on getting a sense of the effect that sample size has on your sampling distribution.

7.  Use the app below to create sampling distributions of proportions of *Doesn't benefit* from samples of size 10, 50, and 100. Use 5,000 simulations. What does each observation in the sampling distribution represent? How does the mean, standard error, and shape of the sampling distribution change as the sample size increases? How (if at all) do these values change if you increase the number of simulations (samples)? (You do not need to include plots in your answer.)

```{r shiny, echo=FALSE, eval=TRUE, results = TRUE}
shinyApp(
  ui <- fluidPage(
    
    # Sidebar with a slider input for number of bins 
    sidebarLayout(
      sidebarPanel(
        
        selectInput("outcome",
                    "Outcome of interest:",
                    choices = c("Benefits", "Doesn't benefit"),
                    selected = "Doesn't benefit"),
        
        numericInput("n_samp",
                     "Sample size:",
                     min = 1,
                     max = nrow(global_monitor),
                     value = 30),
        
        numericInput("n_rep",
                     "Number of samples:",
                     min = 1,
                     max = 30000,
                     value = 15000),
        
        hr(),
        
        sliderInput("binwidth",
                    "Binwidth:",
                    min = 0, max = 0.5,
                    value = 0.02,
                    step = 0.005)
        
      ),
      
      # Show a plot of the generated distribution
      mainPanel(
        plotOutput("sampling_plot"),
        textOutput("sampling_mean"),
        textOutput("sampling_se")
      )
    )
  ),
  
  server <- function(input, output) {
    
    # create sampling distribution
    sampling_dist <- reactive({
      global_monitor %>%
        rep_sample_n(size = input$n_samp, reps = input$n_rep, replace = TRUE) %>%
        count(scientist_work) %>%
        mutate(p_hat = n /sum(n)) %>%
        filter(scientist_work == input$outcome)
    })
    
    # plot sampling distribution
    output$sampling_plot <- renderPlot({
      
      ggplot(sampling_dist(), aes(x = p_hat)) +
        geom_histogram(binwidth = input$binwidth) +
        xlim(0, 1) +
        labs(
          x = paste0("p_hat (", input$outcome, ")"),
          title = "Sampling distribution of p_hat",
          subtitle = paste0("Sample size = ", input$n_samp, " Number of samples = ", input$n_rep)
        ) +
        theme(plot.title = element_text(face = "bold", size = 16))
    })
    
    ggplot(data = sample_props50, aes(x = p_hat)) +
      geom_histogram(binwidth = 0.02) +
      labs(
        x = "p_hat (Doesn't benefit)",
        title = "Sampling distribution of p_hat",
        subtitle = "Sample size = 50, Number of samples = 15000"
      )
    
    # mean of sampling distribution
    output$sampling_mean <- renderText({
      paste0("Mean of sampling distribution = ", round(mean(sampling_dist()$p_hat), 2))
    })
    
    # mean of sampling distribution
    output$sampling_se <- renderText({
      paste0("SE of sampling distribution = ", round(sd(sampling_dist()$p_hat), 2))
    })
  },
  
  options = list(height = 900) 
)
```

------------------------------------------------------------------------

## More Practice

8.  Use the app above to create sampling distributions of proportions of *Benefits* from samples of size 16 and 144. Use 5,000 simulations.  How much smaller is the SE for sample of size 144 compared to size 16?  How does this number relate to $\frac{144}{16} = 9$? 

A good double check for your answer to the question above is to look up the formula for $SE$ of a single categorical variable in your textbook.  Even though you're doing simulations, they should be pretty close to the theoretical methods, and the formula might help you see what I'm looking for in the second part of that question.

9.  The success/failure condition is a little bit arbitrary.  Experiment with the sample size in the app above, and pick the sample size that you think should be the cut-off for when the sample-distribution is normal.  Is your number times 0.2 above or below 10?  Your number times 0.2 is what you think the success/failure condition should be: tell me why you think your number is best.

------------------------------------------------------------------------

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">![Creative Commons License](https://i.creativecommons.org/l/by-sa/4.0/88x31.png){style="border-width:0"}</a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
