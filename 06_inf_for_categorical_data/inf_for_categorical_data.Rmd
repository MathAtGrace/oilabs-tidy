---
title: 'Inference for categorical data'
output:
  html_document:
    css: ../lab.css
    highlight: pygments
    theme: cerulean
    toc: true
    toc_float: true
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, results = FALSE, fig.show = "hide", message = FALSE)
```

## Getting Started

### Load packages

In this lab, we will explore and visualize the data using the **tidyverse** suite of packages, and perform statistical inference using **infer**.
The data can be found in the companion package for OpenIntro resources, **openintro**.  We'll also use a new package called **janitor** that is really useful for creating two-way tables.

Remember to only do this code once in your console:
```{r eval = FALSE}
install.packages(c("janitor", "gt"))
```


Let's load the packages.

```{r load-packages}
library(tidyverse)
library(openintro)
library(infer)
library(janitor)
library(gt)
set.seed(12345)
```

### Creating a reproducible lab report

To create your new lab report, in RStudio, go to New File -\> R Markdown... Then, choose From Template and then choose `Lab Report for OpenIntro Statistics Labs` from the list of templates.

### The data

You will be analyzing the same dataset as in the previous lab, where you delved into a sample from the Youth Risk Behavior Surveillance System (YRBSS) survey, which uses data from high schoolers to help discover health patterns.
The dataset is called `yrbss` which comes with the `openintro` package.  You can check it out with

```{r eval = FALSE}
data(yrbss)
View(yrbss)
```

and you can see more of what the variable names mean by
```{r eval = FALSE}
?yrbss
```

### Exploring the data with tables

First we'll use the `janitor` package to create tables from our categorical data, then we'll use the `gt` package to make our tables pretty.  

1.  Run the code below in your lab report.  Make a mathematical observation about the data.  A "mathematical oberservation" means you should refer to at least one of the numbers.  Remember: your answers to lab reports should always be in complete sentences.

```{r }
yrbss %>%
  tabyl(text_while_driving_30d) %>%
  adorn_pct_formatting() %>%
  gt()
```


2.  You might be annoyed about the order of the groups in the table you made.  This is because R orders categories alphabetically, and `30` comes before `6` alphabetically because $3 < 6$.  We can fix this by manually changing the order of the categories.  Run the code below in your lab report and then rerun the code from exercise 1.

```{r}
yrbss <- yrbss %>%
  mutate(text_while_driving_30d = factor(text_while_driving_30d,
                                         levels = c("did not drive",
                                                    "0", "1-2", "3-5",
                                                    "6-9", "10-19",
                                                    "20-29", "30")),
         helmet_12m = factor(helmet_12m,
                             levels = c("did not ride", "never",
                                        "rarely", "sometimes",
                                        "most of time", "always")))
```

The `janitor` package let's us go a step further than using `count()` like in previous labs, because it can create 2-way tables, and then easily "adorn" them with totals, percentages, etc.

3.  Run the code below in your lab report.  Pick one of the non-total percentages and use it in a complete sentence that gives the context of that number.

```{r}
yrbss %>%
  tabyl(text_while_driving_30d, helmet_12m) %>%
  adorn_totals("row") %>%
  adorn_totals("col") %>%
  adorn_percentages("all") %>%
  adorn_pct_formatting() %>%
  gt()
```

## Inference for Two Proportions

Do you think that people who always wear their helmet are more likely to not text and drive?

Our first problem with answering this question is that both of these questions have more than two options, so we need to recode each of them into only two categories.  We'll break this into steps.  Run this in your console and then look at the both variables to see that they are now only made up of two categories.

```{r}
yrbss %>%
  mutate(text_while_driving_30d = ifelse(text_while_driving_30d == "0",
                                         "0", "not 0"),
         helmet_12m = ifelse(helmet_12m == "always",
                             "always", "not always")) %>%
  specify(response = text_while_driving_30d,
          explanatory = helmet_12m,
          success = "0") %>%
  View()
```

Notice that we took the `yrbss` data and distilled it to two variables with two outcomes each as a new data set called `helmet_vs_no_texting`.  Think about how this was done, because you'll have to do it for two other variables later on.

You also should have received a warning that 1199 rows containing missing values were removed.  If we were doing a real scientific project we would need to note this in our write-up.

Now that we have two variables with two possibilities each, we have a scenario that matches section 6.2 of our book on the difference of two proportions.  We'll use the `infer` package to find our point estimate and create a null distribution to compare it to, and we'll give these the obvious names `point_estimate` and `null_dist` respectively.

To find the point estimate we only need to add one line to the end of the code above.

```{r}
point_estimate <- yrbss %>%
  mutate(text_while_driving_30d = ifelse(text_while_driving_30d == "0",
                                         "0", "not 0"),
         helmet_12m = ifelse(helmet_12m == "always",
                             "always", "not always")) %>%
  specify(response = text_while_driving_30d,
          explanatory = helmet_12m,
          success = "0") %>%
  calculate(stat = "diff in props", order = c("always", "not always"))
```
Now we can create the null distribution with 5000 simulations.  It might take your computer a couple seconds to complete all of the simulations.

```{r}
null_dist <- yrbss %>%
  mutate(text_while_driving_30d = ifelse(text_while_driving_30d == "0",
                                         "0", "not 0"),
         helmet_12m = ifelse(helmet_12m == "always",
                             "always", "not always")) %>%
  specify(response = text_while_driving_30d,
          explanatory = helmet_12m,
          success = "0") %>%
  hypothesize(null = "independence") %>% 
  generate(reps = 5000) %>%
  calculate(stat = "diff in props", order = c("always", "not always"))
```


```{r}
visualize(null_dist) +
  shade_p_value(obs_stat = point_estimate, direction = "two-sided")
```

And we can compute the p-value using our 5000 simulations.

```{r}
null_dist %>%
  get_p_value(obs_stat = point_estimate, direction = "both")
```


1.  Summarize what we just did by first writing the null and alternative hypothesis in words, then pasting the p-value and its plot with all other required code, and finally, by writing a decision and conclusion based on the p-value you computed.

If we wanted the confidence interval instead of doing a hypothesis test, we would do

```{r}
yrbss %>%
  mutate(text_while_driving_30d = ifelse(text_while_driving_30d == "0",
                                         "0", "not 0"),
         helmet_12m = ifelse(helmet_12m == "always",
                             "always", "not always")) %>%
  specify(response = text_while_driving_30d,
          explanatory = helmet_12m,
          success = "0") %>%
  generate(reps = 5000) %>%
  calculate(stat = "diff in props", order = c("always", "not always")) %>%
  get_ci(level = 0.95)
```
2.  Use complete sentences to interpret this confidence interval in context of the survey.  Include the code above.

### On our own: Difference of Two Proportions

Are males or females more likely to say they do not watch TV?

1.  Follow similar steps above to find the confidence interval for the hours of TV watched by females minus the hours of TV watched by males on school nights.  Show your code and interpret your results in context of the data.

2.  Follow similar steps above to follow a hypothesis test to check whether gender and not watching TV are dependent or independent.  Make sure to state your null and alternative hypothesis in English, include your code, and interpret your decision and conclusion.


-----------------------------------------

## How does the proportion affect the margin of error?

Imagine you've set out to survey 1000 people on two questions: are you at least 6-feet tall?
and are you left-handed?
Since both of these sample proportions were calculated from the same sample size, they should have the same margin of error, right?
Wrong!
While the margin of error does change with sample size, it is also affected by the proportion.

Think back to the formula for the standard error: $SE = \sqrt{p(1-p)/n}$.
This is then used in the formula for the margin of error for a 95% confidence interval: $$
ME = 1.96\times SE = 1.96\times\sqrt{p(1-p)/n} \,.
$$ Since the population proportion $p$ is in this $ME$ formula, it should make sense that the margin of error is in some way dependent on the population proportion.
We can visualize this relationship by creating a plot of $ME$ vs. $p$.

Instead of only considering these two variables, let's simulate all possible true proportions rounded to the nearest 100th and plot their 95% M.E.

```{r n-for-me-plot}
n <- 1000 #pick an arbitrary sample size
p <- seq(from = 0, to = 1, by = 0.01) #sequence: 0, 0.01, 0.02, ... 0.99, 1
me <- 2 * sqrt(p * (1 - p)/n) #calculate the margin of error for each p
```

We just calculated a bunch of margins or error for different scenarios.  The best way to get a sense for what they are is to plot them with the `ggplot` function.

```{r me-plot}
dd <- data.frame(p = p, me = me)
ggplot(data = dd, aes(x = p, y = me)) + 
  geom_line() +
  labs(x = "Population Proportion", y = "Margin of Error")
```

1.  Describe the relationship between `p` and `me`. Include the margin of error vs. population proportion plot you constructed in your answer. For which value of `p` is margin of error maximized?



------------------------------------------------------------------------

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">![Creative Commons License](https://i.creativecommons.org/l/by-sa/4.0/88x31.png){style="border-width:0"}</a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
